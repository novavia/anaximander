# Anaximander Mockups

## Smart Factory Use Case

### Assumptions

The application is deployed to monitor the health and productivity of manufacturing machines. Data collected from the factory floor includes messages generated by machine controllers as well as sensor measurements enabled by IoT devices. The application tracks and summarizes plant production from a granular level (i.e. a production job assigned to a single machine and operator) to various aggregated views. Anomalies indicative of possible machine failures are characterized and logged, and a workflow alerts maintenance staff to take corrective actions.

### Data Model and Data Sets

For this application, we recognize the following entities, grouped by functional categories

* Assets:
  * Machine: a manufacturing machine
  * MachineGroup: a logical grouping of machines used for report summarization purposes -a group could be an assembly line, or a set of similar machines, etc.
  * Plant: a site at which the application is deployed
* Instruments:
  * Device: an IoT device that generates sensor data
  * Monitor: a logical assignment of a device to a function and location in the plant
* Environment:
  * Product: a description of a product that the plant may produce
  * Operator: a machine operator
  * Crew: A group of machine operators who work on a common schedule

For each entity, we expect the following attributes:

* Entity-specific attributes, e.g. *make* and *model* for a Machine
* Specs: a set of entity specifications represented as a nested collection. Specs follow a predetermined schema, at least in part -for instance a Machine's specifications is a MachineSpec, which is declared with a nested schema. Compared to regular attributes, specs are more flexible, both because of nesting and the ability to ignore certain attributes or add custom attributes, though the flexibility comes at the cost of indexing capabilities.
* Types: each entity can be assigned a type attribute -for instance, a Machine can have type 'motor' or 'pump'. Types form a hierarchy, but they are distinct from programming types. In other words, all Machine objects in the application's program can be instances of the same Machine class while featuring different machine types.  
* States: entities may also be stateful -even potentially featuring multiple types of states. Like types, states are defined hierarchically. For instance, a Machine's operating state may be "Running", "Idle" or "Offline" at the top-level, with sub-states "Off-Schedule", "Maintenance" and "Unavailable" in the Offline state. Note that in the current scope of Anaximander, there is no immediate plan to make application objects stateful in the sense that they implement callbacks and response behaviors, but entity states can be tracked and published as part of the data pipeline.
* Tags: entities may also implement various tags to allow flexible and arbitrary groupings. Entities can feature any number of tags as words.

Let's now propose the form of the Machine entity declaration:

```python
from anaximander import Entity, Spec, fields, EntityType, State, typedef, statedef

class MachineType(EntityType):  # Definition of application types for Machine objects
    rotating = typedef(abstract=True)  # Provisional syntax inspired by Enum; abstract indicates that
    								   # rotating is a grouping but not an actual type
	motor = typedef(super='rotating')  # This makes the motor type a subtype of the 'rotating' type
    pump = typedef(super='rotating')
    forging_press = typedef(tags={'production'})  # Tags are passed down to instances of that type

class MachineState(State):  # Definition of the 'MachineState' State class
    running = statedef(color='green')  # States take a color attribute for default graphic representations
    idle = statedef(color='white')
    offline = statedef(color='gray')
    off_schedule = statedef(super='offline', color='lightgray')
    maintenance = statedef(super='offline', color='black')
    unavailalble = statedef(super='offline', color='darkgray')

class MachineSpec(Spec):  # Schema definition of specifications for Machine objects
    subtype = fields.String()  # Arbitrary 'subtype', which doesn't follow an enumeration
    schedule = fields.Schedule()  # Definition of Schedule TBD

# A specialization of MachineSpec for rotating machines (fields can be added or modified)
class RotatingMachineSpec(MachineSpec, types=('rotating',)):
    rated_speed = fields.Float(unit='rpm')

class Machine(Entity, etype=MachineType):  # The Machine object schema definition
    name = fields.String()
    make = fields.String()
    model = fields.String()
    # type = fields.Type(MachineType)  # alternative to etype=MachineType as class constructor variable
    group = fields.Parent("MachineGroup")  # Specifies a child-parent relationship with other entity
    									   # Such relationship may admit either a class pointer or a string,
        								   # the latter offered to prevent issues of circular definitions
    op_state = fields.State(MachineState)
    spec = fields.Spec(MachineSpec)
    
# Machine instances are serializable and can also be tabularized into dataframes
```

In addition to entities, the application model entails a number of time-based data sets. These are assumed to all be stored in tabular format -and follow the tabular data archetypes. 

* IoT device data:
  * Device heartbeats: event records
  * Sensor readings: sample records, probably grouped into feature groups
* Machine health monitoring:
  * Anomalies: these are either events (punctual times) or sessions (interval times)
  * Diagnostics: these can be more complex data structure (i.e. nested) attached to a timestamp or time interval
  * Alerts: alerts may be triggered in response to anomalies to warn end users
  * Interventions: maintenance actions (time point) or operations (time interval), logged by end users for cross-referencing
* Production monitoring:
  * Jobs: a job is a session during which a machine or group thereof produces a give product or set thereof. Job information may also incorporate crew / operator references.
* Summaries:
  * State histories for devices, monitors, machines...
  * Counts of various kinds (Production, anomalies, alerts...)
  * Statistical trends (moving average, percentiles...) for sample series

All these data sets are declared as Record subclasses, in very similar fashion to the Entities. In fact Record classes may also implement types, states, specs and tags. The main differences are that Records describe fast-accumulating series and feature timestamps. 

Following are a handful of provisional data set declarations:

```python
from datetime import timedelta
from anaximander.records import Record, Sample, Event, Session, Transition, Periodic
from anaximander import State, statedef, typeparam

class DeviceHeartbeat(Event):
    timestamp = fields.DateTime(sequencer=True)  # sequencer=True indicates that this field is used for sequencing records
    device = fields.Parent("Device", key=True)  # key=True indicates that this field is used as record key

class VibrationsSample(Sample):
    timestamp = fields.DateTime(sequencer=True)
    monitor = fields.Parent("Monitor", key=True)
    accel_x = fields.Acceleration(unit="m/s^2")  # assumes a field type designed for Acceleration quantities
    accel_y = fields.Acceleration(unit="m/s^2")
    accel_z = fields.Acceleration(unit="m/s^2")
    velocity_x = fields.Velocity(unit="m/s")  # assumes a field type designed for Velocity quantities
    velocity_y = fields.Velocity(unit="m/s")
    velocity_z = fields.Velocity(unit="m/s")

    @period									# sets an expected sampling period. This could be a constant, and
    def sampling_period(self):              # in this case we make it monitor-dependent, with the value found in the
        try:								# monitor's spec
        	prd = self.monitor.spec.polling.vibrations
        except AttributeError:
            prd = 0.5
        return timedelta(seconds=prd)

class JobNote(Event):  # Tentative concept to allow more modularity
    timestamp = fields.DateTime(sequencer=True)
    author = fields.Parent("Operator")
    note = fields.String(max_length=4096)
    
class Job(Session):
    start_time = fields.DateTime()
    end_time = fields.DateTime()
    product = fields.Parent("Product")
    machine = fields.Parent("Machine")
    part_count = fields.Count()  # In keeping with levels of measurement theory, a field type exists for counts
    notes = fields.List(JobNote)  # Any number of timestamped notes can be attached
    work_sessions = fields.Log("JobWorkSession")  # This intended to allow breaking the job into multiple subsession
    											  # corresponding to operator changes
        										  # The field type is Log to indicate we expect a table-like object
            									  # The same thing could have been done for notes, and maybe this isn't
                								  # proper / consistent, but at this stage I'm mostly interested in generating
                    							  # examples and options.
                        						  # Yet another possibility would be to use fields.Children -though that
                            					  # appears more applicable to entities
	@sequencer	# alternate definition of sequencer using a decorator and classmethod-like declaration
    def period(cls):
        return (cls.start_time, cls.end_time)  # the sequencer is a tuple for sessions
    
    @key  # alternate definition of record keys using a decorator and classmethod-like declaration
    def job_key(cls):
        return (cls.machine, cls.product)  # this illustrates a composite key
    									   # Not sure how feasible this is if the methods become complex since the goal
        								   # is to read this to generate database schemas with matching indexes
                        
class JobWorkSession(Session):
    job = fields.Parent(Job, key=True)
    start_time = fields.DateTime(sequencer='start')  # This method of declaring sequencer start and end is probably
    end_time = fields.DateTime(sequencer='end')  # easier to handle than a decorator
    operator = fields.Parent("Operator", index=True)  # Indicates that operator is not the record key, but if these records
    												  # are stored in a storage engine that supports multiple indexing, then
        											  # the operator column should be indexed.
    # Note that it would be equally valid to make operator the record key, but that would signal a different intent, i.e. we 		# want to retrieve sequences of work sessions keyed by operators. If storing in a columnar data store, or to interface with 	# a pubsub message broker, then we can only allow a single key -it can be a composite key, but it's still defining a single 	# combination that is used for groupby operations. Here we assume that these sessions are mapped to Jobs.
    # If we also wanted to retrieve work sessions by operator, one solution would be to make another dataset, and then have the 	# data processing pipeline populate both. However the problem changes if we store data in a SQL store or say, BigQuery. In
    # that case we can have multiple indexes and we almost certainly want that. Likewise DynamoDB and I believe Cassandra allow 	# secondary indexes, so here we are saying that job is the primary index and operator is secondary.
    
class Anomaly(Session):
    """A base type for anomalies detected by Monitors."""
    monitor = fields.Parent("Monitor", key=True)
    start_time = fields.DateTime(sequencer='start')
    end_time = fields.DateTime(sequencer='end')
    
class FeatureAnomaly(Anomaly):
    """Represents a time interval during which a feature is out of bounds.
    
    Here we have a session type using a composite key (feature, monitor), which
    is declared inline rather than using the decorator pattern in Job. This works
    unambiguously since there can only be one key.
    I started writing FeatureAnomaly, then added Anomaly as the parent class and I didn't
    modify FeatureAnomaly. One could ask whether 1) we could omit the fields redefinition,
    knowing that I see advantages (less typing and maintenance) and disadvantages (less explicit),
    2) whether the fact that the parent has a singular key and the derived class a composite key
    creates problems.
    In fact, this harps back onto the problems raised by inheritance, and whether this is the right
    pattern here. Basically, we have the following use cases to handle:
    * Two types that share the same structure (e.g. Press and Motor), which was handled with one class and a
    composite type system in the entity definitions
    * Two types of which one is a specialization of the other, with a different structure (present case) -this
    is generally a good candidate for inheritance
    """
    feature = fields.Parent("Feature", key=True)
    monitor = fields.Parent("Monitor", key=True)
    start_time = fields.DateTime(sequencer='start')
    end_time = fields.DateTime(sequencer='end')
    severity = fields.State("Severity", index=True)  # Assumes that a severity state is defined somewhere in the application
    
class AlertState(State):
    open = statedef(color="red")
    acknowledged = statedef(color="orange")
    closed = statedef(color="gray")

class MachineAlert(Event):
    """Represents an alert issued at one point in time to signal an anomaly."""
    machine = fields.Parent("Machine", key=True)
    issue = fields.DateTime(sequencer=True)
    anomaly = fields.Parent(Anomaly, index=True)
    state = fields.State(AlertState)

class MachineStateTransition(Transition):
    """Records transitions in the state of a Machine."""
    machine = fields.Parent("Machine", key=True)
    timestamp = fields.DateTime(sequencer=True)
    state = fields.State("MachineState", target=True)  # target indicates that this is the state targeted by the transition
    
class FeatureSummary(Periodic, parameters=('freq',)):  # Parameters signals a parametric type
    """A generic type for feature summaries of various frequencies"""
    # The Period field type will be linked to pandas Periods. Here we need a reference to the type parameter,
    # and this suggests a function that can act as a placeholder.
    period = fields.Period(sequencer=True, freq=typeparam('freq'))
    monitor = fields.Parent("Monitor", key=True)

@maketypes(freq=['10s', '1min', '5min', '30min', '6h', '1d', '7d', '1M'])  # Directs concrete type creation
class VibrationsSummary(FeatureSummary):
    accel_x_mean = fields.Acceleration(unit="m/s^2")
    accel_x_min = fields.Acceleration(unit="m/s^2")
    accel_x_max = fields.Acceleration(unit="m/s^2")
    [...]
    
```

## Connected Vehicles Use Case

### Assumptions

This application receives driving logs from multiple fleets of vehicles -this is important because each fleet may implement one or more data collection technologies, and hence the semantics, format, sampling frequency and modes of transmission of the source data can all vary. However we always expect a vehicle identifier (possibly anonymized and/or short-lived), a timestamp and a location at a minimum. For the purpose of the example, we'll add a velocity vector as well (speed and heading). Vehicle trajectories are matched onto a street map, which we'll assume to be OpenStreetMap (https://labs.mapbox.com/mapping/osm-data-model/), and the application makes inferences about what is happening on the road network, namely traffic slowdowns and road closures, in order to provide real-time directions and travel time estimates. This in turn suggests that the application builds statistical models from historical data, and updates prior beliefs based on the most recent information.

### Data Model and Data Sets

Here is a list of relevant entities, grouped by category:

* Sources:
  * Fleet: a connected fleet that provides data
  * Vehicle: a member of a fleet
* Map:
  * Way: a road segment
  * Node: a location, in this context limited to intersections where ways connect
  * Route: a particular itinerary on the map, traversing one or more ways

The necessary meta-attributes remain the same as those described in the smart factory use case:

* Specs for complex descriptor that require nesting
* Entity types that can be defined hierarchically and assigned independently from possible inheritance relationships
* State types that can be used for time-dependent attributes
* Tags that can be used as a flexible organizing mechanism. Note that since OpenStreetMap was referenced, the Anaximander tags are of a different nature than the OSM tags -the former are labels, whereas OSM tags are key-value pairs. In order to assign key-value pairs to Anaximander data objects, application designers can either make them first-class attributes or include them in a Spec schema. 

```python
import anaximander as nx

class VehicleType(nx.EntityType):
    car = nx.typedef()
    truck = nx.typedef()
    class_1_truck = nx.typedef(super=truck)
    class_2_truck = nx.typedef(super=truck)

class Vehicle(nx.Entity):
    fleet = nx.fields.Parent("Fleet")
    type = nx.fields.Type(VehicleType)
    specs = nx.fields.Spec("VehicleSpec")

class Node(nx.Entity):
    geom = nx.fields.Point(spatial=True)  # Although it's obvious that a Point attribute is 'spatial',
    									  # the flag actually signals that this is the entity's spatial
        								  # extent, which can be used for representation purposes.
            							  # Technically, an object could have multiple spatial attributes,
                						  # but only one (or none) spatial designation.
    type = nx.fields.Type("NodeType")
    specs = nx.fields.Spec("NodeSpec")

class Way(nx.Entity):
    start_node = nx.fields.Parent(Node)
    end_node = nx.fields.Parent(Node)
    geom = nx.Fields.LineString(spatial=True)
    type = nx.fields.Type("WayType")
    specs = nx.fields.Spec("WaySpec")
    
    @classmethod
    def connected(cls, w0: Way, w1: Way):
        assert w0.end_node == w1.start_node

class Route(nx.Entity):
    ways = nx.fields.List(Way)
    
    # Could this work to declare the entity's spatial extent from a property?
    # One problem with doing that is if we store the Route in a database, there is no direct
    # spatial information available to index it -unless we automatically store the bounding box
    # of its geometry. Or we could add an attribute for that purpose, but then the model becomes
    # denormalized, so that needs to be thought through.
    @nx.spatial  
    @property
    def geom(self):
        return <<<some function that concatenates linestrings>>>

# We need the Ways to be connecting. Of course one possibility is to
# not enforce and assume that Route must be well formed. Another possibility is to add an object-level
# validator (validation should happen at two levels: individual fields, or object, once all the attributes
# have been set). This could look like this:
	@nx.validator
    def validate_ways(self):
        assert all(Way.connected(w0, w1) w0, w1 in zip(self, self))

```



On the records front, we can envision the following data sets:

* Driving logs:
  * Raw driving logs: these are the logs obtained from fleets, which may have different formats. We'll assume that the application implements an ETL pipeline for these logs, using the Anaximander paradigm. Currently Anaximander focuses on data description and storage alone, so in practice the ETL pipeline would be implemented with a different library, but 1) this will change at some point in the future, 2) we'll assume that Anaximander is used for integrating the data stores, hence raw driving logs are described in Anaximander even though the ETL process is coded elsewhere.
  * Normalized driving logs: these are the logs that have been normalized by extracting and renaming common features. Note that the sampling frequency is still vehicle and/or fleet-dependent since GPS loggers operate at different rates.
  * Trips: a trip is basically a driving session for a given vehicle.
  * Traces: a trace is a subset of a trip that is made up of a fully connected driving log, meaning that there is no large spatial gap between consecutive samples -and therefore it can be map-matched.
  * Traversals: a traversal takes place when a vehicle drives over a way. This is a session, and can be used as the basis for travel times collection and estimation.
* Traffic events:
  * Bottlenecks: a bottleneck is defined as a localized slowdown, and is therefore a spacetime session, ie. it has a start and end time, and at every point in time it spans over a route.
  * Closure: a road closure is similar to a bottleneck with two differences: 1) the route is fixed, and 2) its temporality could be more complex than a simple session, as in the case of a work zone that may be scheduled at certain times of the day over multiple days.

```python
from datetime import timedelta
import anaximander as nx
from my_spatial_library import point_distance

class DrivingSample(nx.Sample):
    vehicle = nx.Fields.Parent("Vehicle", key=True)
    timestamp = nx.Fields.DateTime(sequencer=True)
    geom = nx.Fields.GeoPoint(spatial=True)
    speed = nx.Velocity(unit="mph")
    heading = nx.Angle(unit="degrees")

    @classmethod
    def time_gap(cls, s0, s1):
        if s0.timestamp >= s1.timestamp:
            return s0.timestamp - s1.timestamp
       	else:
        	return s1.timestamp - s0.timestamp

    @classmethod
    def spatial_gap(cls, s0, s1):
        return point_distance(s0.geom, s1.gemo)

class DrivingLog(nx.Log[DrivingSample]):

    @property
	def is_trip_like(self):
        max_gap = timedelta("20min")
        assert all(DrivingSample.time_gap(s0, s1) < max_gap for s0, s1 in zip(self, self))
        
    @property
    def is_trace_like(self):
        max_gap = nx.Length('50m')
        assert all(DrivingSample.spatial_gap(s0, s1) < max_gap for s0, s1 in zip(self, self))
    
class Trip(nx.Session):
    vehicle = fields.Parent("Vehicle", key=True)
    start_time = fields.DateTime(sequencer='start')
    end_time = fields.DateTime(sequencer='end')
    samples = fields.Log(DrivingLog, properties=(DrivingLog.is_trip_like))  # This may be over the top...

    # Here we have the same issues as for Route. The geometry is given by the samples, but if we store
    # vehicle trips as elementary records, they also need to be indexed spatially.
    @property
    def geom(self):
        return self.samples.geom

class Trace(nx.Session):
    # Traces are constituent parts of a trip, but the traces are still keyed directly to the Vehicle
    trip = fields.Parent(Trip)
    vehicle = fields.Parent("Vehicle", key=True)
    start_time = fields.DateTime(sequencer='start')
    end_time = fields.DateTime(sequencer='end')
    samples = fields.Log(DrivingLog, properties=(DrivingLog.is_trip_like, DrivingLog.is_trace_like))
    
    
```

